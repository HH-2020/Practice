{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# This project aims on converting one domain 256x256 RGB image to the other domain 256x256 RGB image.\n",
    "# The model is same as GAN.ipynb, but the train method is different.\n",
    "# The code is hardly based on adaddinpersson's project\n",
    "\n",
    "# reference: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "#            https://github.com/aladdinpersson/Machine-Learning-Collection\n",
    "#            https://github.com/yunjey/pytorch-tutorial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from img256\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class DirtyCleanDataset(Dataset):\n",
    "    def __init__(self, root_dirty, root_clean, transform = None):\n",
    "        self.root_dirty = root_dirty\n",
    "        self.root_clean = root_clean\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.dirty_images = os.listdir(root_dirty)\n",
    "        self.clean_images = os.listdir(root_clean)\n",
    "        self.length_dataset = max(len(self.dirty_images),len(self.clean_images))\n",
    "        self.clean_len = len(self.clean_images)\n",
    "        self.dirty_len = len(self.dirty_images)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length_dataset\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        dimage = self.dirty_images[index % self.dirty_len]\n",
    "        cimage = self.clean_images[index % self.clean_len]\n",
    "        \n",
    "        dpath = os.path.join(self.root_dirty, dimage)\n",
    "        cpath = os.path.join(self.root_clean, cimage)\n",
    "        \n",
    "        dimage = np.array(Image.open(dpath).convert(\"RGB\"))\n",
    "        cimage = np.array(Image.open(cpath).convert(\"RGB\"))\n",
    "        \n",
    "        if self.transform:\n",
    "            augmentations = self.transform(image = dimage, image0 = cimage)\n",
    "            dimage = augmentations[\"image\"]\n",
    "            cimage = augmentations[\"image0\"]\n",
    "            \n",
    "        return dimage, cimage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coupled-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "dataroot = '/workspace/datasets/Kaggle'\n",
    "\n",
    "image_size = 256\n",
    "batch_size = 32\n",
    "workers = 3\n",
    "\n",
    "trans = A.Compose(\n",
    "    [\n",
    "        A.Resize(width = image_size, height = 256),\n",
    "        A.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5], max_pixel_value = 255),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    additional_targets={\"image0\":\"image\"}\n",
    ")\n",
    "\n",
    "dataset = DirtyCleanDataset(root_dirty = dataroot+'/train', root_clean = dataroot+'/train_cleaned',transform=trans)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle = True, num_workers = workers)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "real_batch = next(iter(dataloader))\n",
    "# clean image\n",
    "#plt.imshow(np.transpose(real_batch[1][30].cpu(),(1,2,0)))\n",
    "# dirty image\n",
    "#plt.imshow(np.transpose(real_batch[0][30].cpu(),(1,2,0)))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].cpu()[:32], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-renewal",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_batch[0][30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-brown",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "loop = 5\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_channels, features_d):\n",
    "        super(Discriminator,self).__init__()\n",
    "        modules = []\n",
    "        modules.append(nn.Conv2d(input_channels, features_d, kernel_size = 4, stride = 2, padding = 1))\n",
    "        modules.append(nn.LeakyReLU(0.2))\n",
    "        for i in range(loop):\n",
    "            modules.append(self._conv(features_d * (2**i), features_d * (2**(i+1)),4,2,1))\n",
    "        modules.append(nn.Conv2d(features_d * (2**loop), 1, kernel_size = 4, stride = 2, padding = 0))\n",
    "        modules.append(nn.Sigmoid())\n",
    "        self.disc = nn.Sequential(*modules)\n",
    "    \n",
    "    def _conv(self, in_channel, out_channel, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size, stride, padding, bias = False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.LeakyReLU(0.2)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "    \n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_channels, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        modules = []\n",
    "        modules.append(self._dconv(input_channels,features_g,4,2,1))\n",
    "        temp = features_g\n",
    "        for i in range(loop):\n",
    "            #modules.append(self._dconv(int(input_channels / (2**i)), int(features_g / (2**(i+1))),4,2,1))\n",
    "            modules.append(self._dconv(temp, temp*2,4,2,1))\n",
    "            temp = temp * 2\n",
    "        for i in range(loop):\n",
    "            #modules.append(self._uconv(input_channels * (2**i), features_g * (2**(i+1)),4,2,1))\n",
    "            modules.append(self._uconv(int(temp), int(temp / 2),4,2,1))\n",
    "            temp = temp/2\n",
    "        modules.append(self._uconv(int(temp), input_channels,4,2,1))\n",
    "        self.gen = nn.Sequential(*modules) \n",
    "\n",
    "        \n",
    "    def _dconv(self, in_channel, out_channel, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channel, out_channel, kernel_size, stride, padding, bias = False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "    def _uconv(self, in_channel, out_channel, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channel, out_channel, kernel_size, stride, padding, bias = False),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.LeakyReLU(0.2)\n",
    "            )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.gen(x)\n",
    "\n",
    "\n",
    "# as for DCGAN    \n",
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m,(nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            m.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "            \n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "def test():\n",
    "    N, in_channels, H, W = 8, 3, 256, 256\n",
    "    x = torch.randn((N, in_channels, H, W))\n",
    "    disc = Discriminator(in_channels, 8)\n",
    "    #print(disc(x).shape)\n",
    "    assert disc(x).shape == (N, 1, 1, 1), \"Discriminator test failed\"\n",
    "    gen = Generator(in_channels, 8)\n",
    "    z = torch.randn((N, in_channels, H, W))\n",
    "    #print(gen(z).shape)\n",
    "    assert gen(z).shape == (N, in_channels, H, W), \"Generator test failed\"\n",
    "\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "D2C = Generator(input_channels = 3, features_g = 52).to(device)\n",
    "D2C.apply(weights_init)\n",
    "C2D = Generator(input_channels = 3, features_g = 52).to(device)\n",
    "C2D.apply(weights_init)\n",
    "summary(C2D,(3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "DD = Discriminator(input_channels = 3, features_d = 52).to(device)\n",
    "DD.apply(weights_init)\n",
    "DC = Discriminator(input_channels = 3, features_d = 52).to(device)\n",
    "DC.apply(weights_init)\n",
    "summary(DC,(3,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test image\n",
    "\n",
    "Test = DirtyCleanDataset(root_dirty = dataroot+'/train', root_clean = dataroot+'/test',transform=trans)\n",
    "\n",
    "Testloader = torch.utils.data.DataLoader(Test, batch_size=32, shuffle = True, num_workers = workers)\n",
    "\n",
    "test_batch = next(iter(Testloader))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(test_batch[1].cpu(), padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "Learning_rate = 1e-4\n",
    "Channels_img = 3\n",
    "Features_dis = 52\n",
    "Feature_gen = 52\n",
    "Num_epochs = 10\n",
    "beta1 = 0.5\n",
    "lambda_cycleloss = 0.1\n",
    "lambda_identityloss = 0.1\n",
    "\n",
    "\n",
    "opt_Gen = optim.Adam(list(D2C.parameters()) + list(C2D.parameters()), lr = Learning_rate, betas = (beta1, 0.999))\n",
    "opt_Dis = optim.Adam(list(DD.parameters()) + list(DC.parameters()), lr = Learning_rate, betas = (beta1, 0.999))\n",
    "\n",
    "Dis_scaler = torch.cuda.amp.GradScaler()\n",
    "Gen_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "criterion_ = nn.BCEWithLogitsLoss()\n",
    "criterion1 = nn.MSELoss()\n",
    "criterion2 = nn.L1Loss()\n",
    "\n",
    "#writer_dirty = SummaryWriter(f\"/workspace/practice/GAN/dirty\")\n",
    "#writer_clean = SummaryWriter(f\"/workspace/practice/GAN/clean\")\n",
    "\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "img_list = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Train: ...\")\n",
    "\n",
    "for epoch in range(Num_epochs):\n",
    "    for batch_idx, (dirty,clean) in enumerate(dataloader, 0):\n",
    "        clean = clean.to(device)\n",
    "        dirty = dirty.to(device)\n",
    "\n",
    "        #Train the Two Discriminator DC, DD:\n",
    "        #DC : figure out ture clean and fake clean\n",
    "        #DD : figure out ture dirty and fake dirty\n",
    "        with torch.cuda.amp.autocast():\n",
    "            \n",
    "            #Loss DC:\n",
    "            dirty_clean = D2C(dirty)\n",
    "            disC_fake = DC(dirty_clean.detach())\n",
    "            disC_real = DC(clean)\n",
    "            disC_real_loss = criterion1(disC_real, torch.ones_like(disC_real))\n",
    "            disC_fake_loss = criterion1(disC_fake, torch.zeros_like(disC_fake))\n",
    "            DC_loss = disC_real_loss + disC_fake_loss\n",
    "            \n",
    "            #Loss DD:\n",
    "            clean_dirty = C2D(clean)\n",
    "            disD_fake = DD(clean_dirty.detach())\n",
    "            disD_real = DD(dirty)\n",
    "            disD_real_loss = criterion1(disD_real, torch.ones_like(disD_real))\n",
    "            disD_fake_loss = criterion1(disD_fake, torch.zeros_like(disC_fake))\n",
    "            DD_loss = disD_real_loss + disD_fake_loss\n",
    "            \n",
    "            Dis_loss = (DD_loss + DC_loss)/2\n",
    "            \n",
    "        opt_Dis.zero_grad()\n",
    "        Dis_scaler.scale(Dis_loss).backward()\n",
    "        Dis_scaler.step(opt_Dis)\n",
    "        Dis_scaler.update()\n",
    "        \n",
    "        \n",
    "        #Train the Two Generator D2C, C2D:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            \n",
    "            # adversial loss\n",
    "            DisC_fake = DC(dirty_clean)\n",
    "            DisD_fake = DD(clean_dirty)\n",
    "            loss_D2C_DC = criterion1(DisC_fake, torch.ones_like(DisC_fake))\n",
    "            loss_C2D_DD = criterion1(DisD_fake, torch.ones_like(DisD_fake))\n",
    "        \n",
    "            # cycle consistance loss\n",
    "            re_dirty = C2D(dirty_clean)\n",
    "            re_clean = D2C(clean_dirty)\n",
    "            cycle_dirty_loss = criterion2(dirty, re_dirty)\n",
    "            cycle_clean_loss = criterion2(clean, re_clean)\n",
    "            \n",
    "            # identity loss\n",
    "            identity_dirty = C2D(dirty)\n",
    "            identity_clean = D2C(clean)\n",
    "            identity_dirty_loss = criterion2(dirty, identity_dirty)\n",
    "            identity_clean_loss = criterion2(clean, identity_clean)\n",
    "            \n",
    "            Gen_loss = (loss_D2C_DC + loss_C2D_DD\n",
    "                        + lambda_cycleloss* cycle_dirty_loss + lambda_cycleloss * cycle_clean_loss \n",
    "                        + lambda_identityloss * identity_dirty_loss + lambda_identityloss * identity_clean_loss)\n",
    "            \n",
    "        opt_Gen.zero_grad()\n",
    "        Gen_scaler.scale(Gen_loss).backward()\n",
    "        Gen_scaler.step(opt_Gen)\n",
    "        Gen_scaler.update\n",
    "            \n",
    "        if batch_idx % 1 == 0:\n",
    "            print(f\"Epoch: [{epoch}/{Num_epochs}],  Batch: [{batch_idx}/{len(dataloader)}],  Loss_D: {Dis_loss:.4f},  Loss_G: {Gen_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(DD.state_dict(), './DD.pth')\n",
    "torch.save(DC.state_dict(), './DC.pth')\n",
    "torch.save(D2C.state_dict(), './D2C.pth')\n",
    "torch.save(C2D.state_dict(), './C2D.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-exposure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-conclusion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclegan",
   "language": "python",
   "name": "cyclegan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
